# -*- coding: utf-8 -*-
"""RESNET.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pjxeqbkv-1uOPl8Zje6eo6BLRSQm_8Bv
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import time

# Load CIFAR-10 dataset
(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()

# CIFAR-10 class names
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# Visualize sample images
plt.figure(figsize=(12, 8))
for i in range(20):
    plt.subplot(4, 5, i + 1)
    plt.imshow(x_train[i])
    plt.title(f"{class_names[y_train[i][0]]}")
    plt.axis('off')
plt.suptitle('Sample CIFAR-10 Images', fontsize=16)
plt.tight_layout()
plt.show()

# Class distribution
plt.figure(figsize=(10, 6))
unique, counts = np.unique(y_train, return_counts=True)
plt.bar([class_names[i] for i in unique], counts)
plt.title('CIFAR-10 Training Set - Class Distribution')
plt.xlabel('Classes')
plt.ylabel('Number of Images')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

sample_size = 20000
indices = np.random.choice(len(x_train_full), sample_size, replace=False)
x_train_sampled = x_train_full[indices]
y_train_sampled = y_train_full[indices]

# Convert to float and normalize
x_train_sampled = x_train_sampled.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Convert labels to categorical
y_train_sampled = keras.utils.to_categorical(y_train_sampled, 10)
y_test = keras.utils.to_categorical(y_test, 10)

# Create validation split
val_split = 0.2
val_samples = int(len(x_train_sampled) * val_split)

x_val = x_train_sampled[:val_samples]
y_val = y_train_sampled[:val_samples]
x_train = x_train_sampled[val_samples:]
y_train = y_train_sampled[val_samples:]

def create_model(strategy='feature_extraction'):
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    if strategy == 'feature_extraction':
        base_model.trainable = False

    # Add preprocessing layer that resizes on-the-fly
    model = keras.Sequential([
        layers.Resizing(224, 224, input_shape=(32, 32, 3)),  # Resize during training
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.3),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.2),
        layers.Dense(10, activation='softmax')
    ])

    return model

# Create and compile model
model_fe = create_model('feature_extraction')
model_fe.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Simple callbacks
callbacks = [
    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),
    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)
]

history_fe = model_fe.fit(x_train, y_train,  # Use original 32x32 images
    batch_size=32,
    epochs=10,
    validation_data=(x_val, y_val),  # Original 32x32 images
    callbacks=callbacks,
    verbose=1
)

model_ft = create_model('fine_tuning')
model_ft.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Lower LR for fine-tuning
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history_ft = model_ft.fit(
    x_train, y_train,  # Use original 32x32 images
    batch_size=32,
    epochs=10,
    validation_data=(x_val, y_val),
    callbacks=callbacks,
    verbose=1
)

# =============================================================================
# 5. RESULTS COMPARISON
# =============================================================================

print("\n" + "="*50)
print("RESULTS COMPARISON")
print("="*50)

# Plot training history
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Accuracy plot
axes[0].plot(history_fe.history['accuracy'], 'o-', label='Feature Extraction (Train)')
axes[0].plot(history_fe.history['val_accuracy'], 'o-', label='Feature Extraction (Val)')
axes[0].plot(history_ft.history['accuracy'], 's-', label='Fine-tuning (Train)')
axes[0].plot(history_ft.history['val_accuracy'], 's-', label='Fine-tuning (Val)')
axes[0].set_title('Model Accuracy Comparison')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Accuracy')
axes[0].legend()
axes[0].grid(True)

# Loss plot
axes[1].plot(history_fe.history['loss'], 'o-', label='Feature Extraction (Train)')
axes[1].plot(history_fe.history['val_loss'], 'o-', label='Feature Extraction (Val)')
axes[1].plot(history_ft.history['loss'], 's-', label='Fine-tuning (Train)')
axes[1].plot(history_ft.history['val_loss'], 's-', label='Fine-tuning (Val)')
axes[1].set_title('Model Loss Comparison')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Loss')
axes[1].legend()
axes[1].grid(True)

plt.tight_layout()
plt.show()

# Print results
fe_best_acc = max(history_fe.history['val_accuracy'])
ft_best_acc = max(history_ft.history['val_accuracy'])

print(f"\nFEATURE EXTRACTION:")
print(f"  Best Validation Accuracy: {fe_best_acc:.4f}")

print(f"\nFINE-TUNING:")
print(f"  Best Validation Accuracy: {ft_best_acc:.4f}")

improvement = (ft_best_acc - fe_best_acc) * 100
print(f"\nImprovement from Fine-tuning: {improvement:.2f}%")

# =============================================================================
# 6. TEST SET EVALUATION
# =============================================================================

print("\n" + "="*50)
print("TEST SET EVALUATION")
print("="*50)

# Use best model
best_model = model_ft if ft_best_acc > fe_best_acc else model_fe
best_name = "Fine-tuning" if ft_best_acc > fe_best_acc else "Feature Extraction"

print(f"Best model: {best_name}")

# Evaluate on test set
test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")

# Generate predictions for classification report
y_pred = best_model.predict(x_test, verbose=0)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Print classification report
print("\nClassification Report:")
print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))